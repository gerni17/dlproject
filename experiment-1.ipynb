{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "from preprocessing.image_transform import ImageTransform\n",
    "from preprocessing.seg_transforms import SegImageTransform\n",
    "from datasets.monet import MonetDataModule\n",
    "from datasets.agri import AgriDataModule\n",
    "from systems.cycle_gan_system import CycleGANSystem\n",
    "from models.generators import CycleGANGenerator\n",
    "from models.discriminators import CycleGANDiscriminator\n",
    "from utils.weight_initializer import init_weights\n",
    "from datasets.gogoll import GogollDataModule\n",
    "import os, glob, random\n",
    "\n",
    "from models.unet_light_semseg import UnetLight\n",
    "from datasets.generated import GeneratedDataModule\n",
    "from datasets.mixed import MixedDataModule\n",
    "from datasets.mixed import MixedDataset\n",
    "from datasets.crossval import CrossValidationDataModule\n",
    "from datasets.source import SourceDataModule\n",
    "\n",
    "from systems.gogoll_system import GogollSystem\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = './data'\n",
    "domain = \"domainB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\n",
    "        \"G\": 0.0002,\n",
    "        \"D\": 0.0002,\n",
    "        \"seg_s\": 0.0002,\n",
    "        \"seg_t\": 0.0002,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-Models  -----------------------------------------------------------------\n",
    "seg_net_s = UnetLight()\n",
    "seg_net_t = UnetLight()\n",
    "G_basestyle = CycleGANGenerator(filter=32)\n",
    "G_stylebase = CycleGANGenerator(filter=32)\n",
    "D_base = CycleGANDiscriminator(filter=32)\n",
    "D_style = CycleGANDiscriminator(filter=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogoll_net_config = {\n",
    "        \"G_s2t\": G_basestyle,\n",
    "        \"G_t2s\": G_stylebase,\n",
    "        \"D_source\": D_base,\n",
    "        \"D_target\": D_style,\n",
    "        \"seg_s\": seg_net_s,\n",
    "        \"seg_t\": seg_net_t,\n",
    "        \"lr\": lr,\n",
    "        \"reconstr_w\": 10,\n",
    "        \"id_w\": 2,\n",
    "        \"seg_w\": 0.8\n",
    "    }\n",
    "main_system = GogollSystem(**gogoll_net_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape torch.Size([8, 3, 256, 256]), torch.Size([8, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "transform = SegImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "# Source domain datamodule\n",
    "source_dm = SourceDataModule(data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Generated images datamodule\n",
    "generated_dm = GeneratedDataModule(main_system.G_s2t, data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Mix both datamodules\n",
    "mixed_dm = GogollDataModule(data_dir, domain, transform, batch_size)  # used for training\n",
    "mixed_dm.prepare_data()\n",
    "mixed_dm.setup()\n",
    "dataloader = mixed_dm.train_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetLight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 256, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "soft = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = IoULoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = torch.argmax(r, dim=1)\n",
    "r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(r2, style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = KFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = []\n",
    "for i in range(len(dms)):\n",
    "    all_datasets.append(dms[i].full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_datasets = ConcatDataset(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in self.cv_splitter.split(conc_datasets):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MixedDataset([x.dataset for x in train_loaders])\n",
    "val_dataset = MixedDataset([x.dataset for x in val_loaders])\n",
    "test_dataset = MixedDataset([x.dataset for x in test_loaders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4506cc3c5125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call first initialization function before we start asking for data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call second initialization function before we start asking for data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
     ]
    }
   ],
   "source": [
    "transform = SegImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "# Source domain datamodule\n",
    "source_dm = SourceDataModule(data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Generated images datamodule\n",
    "generated_dm = GeneratedDataModule(main_system.G_s2t, data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Mix both datamodules\n",
    "mixed_dm = MixedDataModule(\n",
    "    source_dm,\n",
    "    generated_dm,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dm.prepare_data() # call first initialization function before we start asking for data\n",
    "dm.setup() # call second initialization function before we start asking for data\n",
    "\n",
    "dataloader = dm.train_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.set_active_split(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dm.test_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"exp\", \"rgb\", \"*.png\")\n",
    "        )\n",
    "segmentation_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"exp\", \"semseg\", \"*.png\")\n",
    "        )\n",
    "target_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"other_domains\", \"domainA\", \"*.jpg\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = KFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_paths_np = np.array(rgb_paths)\n",
    "seg_paths_np = np.array(segmentation_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train_splits = []\n",
    "seg_train_splits = []\n",
    "rgb_test_splits = []\n",
    "seg_test_splits = []\n",
    "train_datasets = []\n",
    "test_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv_splitter.split(rgb_paths):\n",
    "    X_train, X_test = rgb_paths_np[train_index], rgb_paths_np[test_index]\n",
    "    y_train, y_test = seg_paths_np[train_index], seg_paths_np[test_index]\n",
    "    rgb_train_splits.append(X_train.tolist())\n",
    "    rgb_test_splits.append(X_test.tolist())\n",
    "    seg_train_splits.append(y_train.tolist())\n",
    "    seg_test_splits.append(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    train_dataset = SourceDataset(\n",
    "        rgb_train_splits[i],\n",
    "        seg_train_splits[i],\n",
    "        transform,\n",
    "        \"train\")\n",
    "    train_datasets.append(train_dataset)\n",
    "\n",
    "for i in range(5):\n",
    "    test_dataset = SourceDataset(\n",
    "        rgb_test_splits[i],\n",
    "        seg_test_splits[i],\n",
    "        transform,\n",
    "        \"train\")\n",
    "    test_datasets.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataLoader(\n",
    "            test_datasets[4],\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=4)\n",
    "batch = next(iter(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train, rgb_val, seg_train, seg_val = train_test_split(rgb_paths, segmentation_paths, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1 , 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'IOU Metric': 0.530657172203064}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['IOU Metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\n",
    "        \"G\": 0.0002,\n",
    "        \"D\": 0.0002,\n",
    "        \"seg_s\": 0.0002,\n",
    "        \"seg_t\": 0.0002,\n",
    "    }\n",
    "# Sub-Models  -----------------------------------------------------------------\n",
    "seg_net_s = UnetLight()\n",
    "seg_net_t = UnetLight()\n",
    "G_basestyle = CycleGANGenerator(filter=32)\n",
    "G_stylebase = CycleGANGenerator(filter=32)\n",
    "D_base = CycleGANDiscriminator(filter=32)\n",
    "D_style = CycleGANDiscriminator(filter=32)\n",
    "\n",
    "gogoll_net_config = {\n",
    "        \"G_s2t\": G_basestyle,\n",
    "        \"G_t2s\": G_stylebase,\n",
    "        \"D_source\": D_base,\n",
    "        \"D_target\": D_style,\n",
    "        \"seg_s\": seg_net_s,\n",
    "        \"seg_t\": seg_net_t,\n",
    "        \"lr\": lr,\n",
    "        \"reconstr_w\": 10,\n",
    "        \"id_w\": 2,\n",
    "        \"seg_w\": 0.8\n",
    "    }\n",
    "main_system = GogollSystem(**gogoll_net_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SegImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "# Source domain datamodule\n",
    "source_dm = SourceDataModule(data_dir, transform,batch_size=1, split=False, max_imgs=200)\n",
    "# Generated images datamodule\n",
    "generated_dm = GeneratedDataModule(main_system.G_s2t, data_dir, transform, batch_size=1, split=False, max_imgs=200)\n",
    "# Mix both datamodules\n",
    "mixed_dm = MixedDataModule(\n",
    "    source_dm,\n",
    "    generated_dm,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "# Mix both datamodules\n",
    "cv_dm = CrossValidationDataModule(\n",
    "    mixed_dm,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "cv_dm.prepare_data()\n",
    "cv_dm.setup()\n",
    "dataloader = cv_dm.train_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(source_dm.val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SegImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "# Source domain datamodule\n",
    "source_dm = SourceDataModule(data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Generated images datamodule\n",
    "generated_dm = GeneratedDataModule(main_system.G_s2t, data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Mix both datamodules\n",
    "mixed_dm = MixedDataModuleCV(\n",
    "    source_dm,\n",
    "    generated_dm,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "mixed_dm.prepare_data()\n",
    "mixed_dm.setup()\n",
    "dataloader = mixed_dm.train_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split([1,2,3,4], [11,22,33,44], test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)\n",
    "print(x_val)\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = KFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = []\n",
    "for i in range(len(dms)):\n",
    "    all_datasets.append(dms[i].full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_datasets = ConcatDataset(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in self.cv_splitter.split(conc_datasets):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MixedDataset([x.dataset for x in train_loaders])\n",
    "val_dataset = MixedDataset([x.dataset for x in val_loaders])\n",
    "test_dataset = MixedDataset([x.dataset for x in test_loaders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SegImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "# Source domain datamodule\n",
    "source_dm = SourceDataModule(data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Generated images datamodule\n",
    "generated_dm = GeneratedDataModule(main_system.G_s2t, data_dir, transform, batch_size=1, max_imgs=200)\n",
    "# Mix both datamodules\n",
    "mixed_dm = MixedDataModule(\n",
    "    source_dm,\n",
    "    generated_dm,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dm.prepare_data() # call first initialization function before we start asking for data\n",
    "dm.setup() # call second initialization function before we start asking for data\n",
    "\n",
    "dataloader = dm.train_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.set_active_split(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dm.test_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['source_segmentation'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"exp\", \"rgb\", \"*.png\")\n",
    "        )\n",
    "segmentation_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"exp\", \"semseg\", \"*.png\")\n",
    "        )\n",
    "target_paths = glob.glob(\n",
    "            os.path.join(\"./data\", \"other_domains\", \"domainA\", \"*.jpg\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = KFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_paths_np = np.array(rgb_paths)\n",
    "seg_paths_np = np.array(segmentation_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train_splits = []\n",
    "seg_train_splits = []\n",
    "rgb_test_splits = []\n",
    "seg_test_splits = []\n",
    "train_datasets = []\n",
    "test_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv_splitter.split(rgb_paths):\n",
    "    X_train, X_test = rgb_paths_np[train_index], rgb_paths_np[test_index]\n",
    "    y_train, y_test = seg_paths_np[train_index], seg_paths_np[test_index]\n",
    "    rgb_train_splits.append(X_train.tolist())\n",
    "    rgb_test_splits.append(X_test.tolist())\n",
    "    seg_train_splits.append(y_train.tolist())\n",
    "    seg_test_splits.append(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    train_dataset = SourceDataset(\n",
    "        rgb_train_splits[i],\n",
    "        seg_train_splits[i],\n",
    "        transform,\n",
    "        \"train\")\n",
    "    train_datasets.append(train_dataset)\n",
    "\n",
    "for i in range(5):\n",
    "    test_dataset = SourceDataset(\n",
    "        rgb_test_splits[i],\n",
    "        seg_test_splits[i],\n",
    "        transform,\n",
    "        \"train\")\n",
    "    test_datasets.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataLoader(\n",
    "            test_datasets[4],\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=4)\n",
    "batch = next(iter(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train, rgb_val, seg_train, seg_val = train_test_split(rgb_paths, segmentation_paths, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "transform = ImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "\n",
    "dm = AgriDataModule(data_dir, transform, batch_size, domain=domain)\n",
    "dm.prepare_data() # call first initialization function before we start asking for data\n",
    "dm.setup() # call second initialization function before we start asking for data\n",
    "\n",
    "dataloader = dm.test_dataloader() # get the loader that returns us data\n",
    "batch = next(iter(dataloader)) # ask for the next batch of data\n",
    "base, style = (batch['source'], batch['target'])\n",
    "\n",
    "print('Input Shape {}, {}'.format(base.size(), style.size())) # check the shapes of the batch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = make_grid(base, nrow=4, padding=2).permute(1, 2, 0).detach().numpy()\n",
    "temp = temp * 0.5 + 0.5\n",
    "temp = temp * 255.0\n",
    "temp = temp.astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8), facecolor='w')\n",
    "plt.imshow(temp)\n",
    "plt.axis('off')\n",
    "plt.title('Source Domain')\n",
    "plt.show()\n",
    "\n",
    "temp = make_grid(style, nrow=4, padding=2).permute(1, 2, 0).detach().numpy()\n",
    "temp = temp * 0.5 + 0.5\n",
    "temp = temp * 255.0\n",
    "temp = temp.astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8), facecolor='w')\n",
    "plt.imshow(temp)\n",
    "plt.axis('off')\n",
    "plt.title('Target Domain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet_light_semseg import UnetLight\n",
    "from systems.final_seg_system import FinalSegSystem\n",
    "from preprocessing.seg_transforms import SegImageTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "seg_net = UnetLight()\n",
    "seg_system = FinalSegSystem(seg_net, lr=0.1)\n",
    "transform = SegImageTransform(img_size=256)\n",
    "dm = SourceDataModule(data_dir, transform, batch_size, max_imgs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:50: LightningDeprecationWarning: `reload_dataloaders_every_epoch` is deprecated in v1.4 and will be removed in v1.6. Please use `reload_dataloaders_every_n_epochs` in Trainer.\n",
      "  \"`reload_dataloaders_every_epoch` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=False,\n",
    "    max_epochs=1,\n",
    "    gpus=0,\n",
    "    checkpoint_callback=False,\n",
    "    reload_dataloaders_every_epoch=True,\n",
    "    num_sanity_val_steps=0,  # Skip Sanity Check\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.fit(seg_system, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your test_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe00bbdf658f41c89846321b7ec57148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'IOU Metric': 0.32324981689453125}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = trainer.test(seg_system, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32324981689453125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]['IOU Metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config  -----------------------------------------------------------------\n",
    "transform = ImageTransform(img_size=256)\n",
    "batch_size = 8\n",
    "lr = {\n",
    "    'G': 0.0002,\n",
    "    'D': 0.0002\n",
    "}\n",
    "epoch = 1\n",
    "seed = 42\n",
    "reconstr_w = 10\n",
    "id_w = 2\n",
    "\n",
    "# DataModule  -----------------------------------------------------------------\n",
    "dm = SourceDataModule(data_dir, transform, batch_size)\n",
    "viz_set = SourceDataModule(data_dir, transform, 4)\n",
    "\n",
    "G_basestyle = CycleGANGenerator(filter=32)\n",
    "G_stylebase = CycleGANGenerator(filter=32)\n",
    "D_base = CycleGANDiscriminator(filter=32)\n",
    "D_style = CycleGANDiscriminator(filter=32)\n",
    "\n",
    "# Init Weight  --------------------------------------------------------------\n",
    "for net in [G_basestyle, G_stylebase, D_base, D_style]:\n",
    "    init_weights(net, init_type='normal')\n",
    "\n",
    "# LightningModule  --------------------------------------------------------------\n",
    "vs = AgriDataModule(data_dir, transform, batch_size, domain=domain)\n",
    "model = UnetLight()\n",
    "# Trainer  --------------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    logger=False,\n",
    "    max_epochs=epoch,\n",
    "    gpus=0,\n",
    "    checkpoint_callback=False,\n",
    "    reload_dataloaders_every_epoch=True,\n",
    "    num_sanity_val_steps=0,  # Skip Sanity Check\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "970b6d1045365541d5720985b752e91a341d480eea884bbd96abb60afbec2006"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
